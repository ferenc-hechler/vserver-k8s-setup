{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5acf66-8ff9-4d6f-9d94-f36e3a90c38d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.244.0.67\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from cryptography.fernet import Fernet\n",
    "import base64\n",
    "import socket\n",
    "import os\n",
    "\n",
    "OWN_IP=socket.gethostbyname(socket.gethostname())\n",
    "#os.environ[\"HOSTNAME\"]=\"10.244.0.86\"\n",
    "os.environ[\"SPARK_LOCAL_IP\"]=OWN_IP\n",
    "!echo $SPARK_LOCAL_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c222ace9-fd01-4b19-9d67-e6f686806fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID='AKIAYGAQNRJ6BF5ZXRBV'\n",
    "AWS_SECRET_ACCESS_KEY_ENC='gAAAAABj9-WHrLBDqR8Pp3wFNx8TpKzDg25NsLTxHUh7XsgrvvwiQkVCW0ASyZdj6lj3IF7AUTkTZJGtYoWKNC1vXuA6FAmVyXVmZLqOeisXJBKD1eBxgOePtkh1zGk1_YnfmRjypnhI'\n",
    "AWS_SECRET_ACCESS_KEY = Fernet(base64.b64encode((socket.gethostname()*32)[:32].encode('ascii')).decode('ascii')).decrypt(AWS_SECRET_ACCESS_KEY_ENC.encode('ascii')).decode('ascii')\n",
    "AWS_DEFAULT_REGION='eu-central-1'\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=AWS_SECRET_ACCESS_KEY\n",
    "os.environ['AWS_DEFAULT_REGION']=AWS_DEFAULT_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c24dc7b-e5ca-4d58-84c5-cea3b12421b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"spark://bit-spark-master-svc.spark.svc.cluster.local:7077\").config(\"spark.driver.host\", OWN_IP).config(\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY_ID).config(\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY).config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\").appName(\"FerisSparkSession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "772a3e01-d658-4c44-a0f0-3c34c6e4ab91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "#sc.setLogLevel(\"DEBUG\")\n",
    "sc.setLogLevel(\"WARN\")\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "243fb596-40aa-451c-bdca-e13c252b4ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "from pyspark.ml.feature import RegexTokenizer, VectorAssembler, Normalizer, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import concat, col, lit, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# 2) run the cells below to read the dataset and extract description length features\n",
    "# 3) write code to answer the quiz questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "711bf70a-9e12-4b93-a975-2244686787d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, Id: bigint, Tags: string, Title: string, oneTag: string]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_data = \"s3a://feris-udacity-spark-project/stackexchange/Train_onetag_small.json\"\n",
    "df = spark.read.json(stack_overflow_data)\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "087d44fa-6c3e-467a-92bb-3b23e4eef632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Body', StringType(), True), StructField('Id', LongType(), True), StructField('Tags', StringType(), True), StructField('Title', StringType(), True), StructField('oneTag', StringType(), True)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a44a95e-23b4-4d29-8374-4e4d5e93da2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Body=\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", Id=1, Tags='php image-processing file-upload upload mime-types', Title='How to check if an uploaded file is an image without mime type?', oneTag='php')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2eae63d-159d-4718-a6d1-238d0d146d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Desc\", concat(col(\"Title\"), lit(' '), col(\"Body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee7f6b25-bb22-469c-83d4-4dcdbc53530c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body_length = udf(lambda x: len(x), IntegerType())\n",
    "df = df.drop(col(\"words\"))\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Desc\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "df = regexTokenizer.transform(df)\n",
    "df = df.withColumn(\"DescLength\", body_length(df.words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33abbbac-e41e-491e-a35a-96115fd7574b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"DescLength\"], outputCol=\"DescVec\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c591b797-1642-4aca-950f-bea7c8ffa9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753.2\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer this question\n",
    "from pyspark.sql.functions import min, max\n",
    "minmax = df.select(min(\"DescLength\"), max(\"DescLength\")).collect()[0]\n",
    "print(minmax[1]/minmax[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f5570f9-3858-4392-a14c-2b2c301acdf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanstd: 180.28187, stddev: 192.10819533505136\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer this question\n",
    "from pyspark.sql.functions import avg, stddev\n",
    "meanstd = df.select(avg(\"DescLength\"), stddev(\"DescLength\")).collect()[0]\n",
    "print(f\"meanstd: {meanstd[0]}, stddev: {meanstd[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5bf3633-06a4-4309-83c8-e41a3811086e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.57780398800969s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(Body=\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", Id=1, Tags='php image-processing file-upload upload mime-types', Title='How to check if an uploaded file is an image without mime type?', oneTag='php', Desc=\"How to check if an uploaded file is an image without mime type? <p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", words=['how', 'to', 'check', 'if', 'an', 'uploaded', 'file', 'is', 'an', 'image', 'without', 'mime', 'type', 'p', 'i', 'd', 'like', 'to', 'check', 'if', 'an', 'uploaded', 'file', 'is', 'an', 'image', 'file', 'e', 'g', 'png', 'jpg', 'jpeg', 'gif', 'bmp', 'or', 'another', 'file', 'the', 'problem', 'is', 'that', 'i', 'm', 'using', 'uploadify', 'to', 'upload', 'the', 'files', 'which', 'changes', 'the', 'mime', 'type', 'and', 'gives', 'a', 'text', 'octal', 'or', 'something', 'as', 'the', 'mime', 'type', 'no', 'matter', 'which', 'file', 'type', 'you', 'upload', 'p', 'p', 'is', 'there', 'a', 'way', 'to', 'check', 'if', 'the', 'uploaded', 'file', 'is', 'an', 'image', 'apart', 'from', 'checking', 'the', 'file', 'extension', 'using', 'php', 'p'], DescLength=96, DescVec=DenseVector([96.0]), DescGroup=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: write your code to answer this question\n",
    "import time\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "silhouette_score=[]\n",
    "\n",
    "df = df.drop(col(\"DescGroup\"))\n",
    "\n",
    "KMeans_algo = KMeans(featuresCol='DescVec', predictionCol=\"DescGroup\", k=5, seed=42)\n",
    "start = time.perf_counter()\n",
    "KMeans_fit = KMeans_algo.fit(df)\n",
    "df = KMeans_fit.transform(df)\n",
    "stop = time.perf_counter()\n",
    "print(f'{stop-start}s')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e488f3e7-7667-4989-8f6d-2571ae89985b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_counts = udf(lambda x: len(x.split(\" \")), IntegerType())\n",
    "df = df.withColumn(\"NumTags\", word_counts(df.Tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4de40e41-770c-4b22-8b1e-adf9ea359bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+-----------------+\n",
      "|DescGroup|   avg(DescLength)|      avg(NumTags)|count(DescLength)|\n",
      "+---------+------------------+------------------+-----------------+\n",
      "|        0| 94.99131134352373|2.7399356395816574|            62150|\n",
      "|        4|233.61611668563154| 3.079445536360815|            29001|\n",
      "|        1| 479.0754844829923| 3.233771513755251|             7379|\n",
      "|        3|1033.2246320681643| 3.284275755228505|             1291|\n",
      "|        2|2683.7150837988825|3.3854748603351954|              179|\n",
      "+---------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.groupby(\"DescGroup\").agg(avg(col(\"DescLength\")), avg(col(\"NumTags\")), count(col(\"DescLength\"))).orderBy(\"avg(DescLength)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e859fdd-ef9c-4ee6-a62b-08cae63210a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(df.DescGroup == 3).sort(\"DescLength\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2b9bed6-75ad-41df-b9a5-5e83ccef477e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3s=df.where(df.DescGroup == 3).sort(\"DescLength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5182af71-e73e-4bac-998b-244230c3f55a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, Id: bigint, Tags: string, Title: string, oneTag: string, Desc: string, words: array<string>, DescLength: int, DescVec: vector, DescGroup: int, NumTags: int]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3s.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0dc3af1-8683-41be-a36b-1bbf5d204b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([94.99131134]),\n",
       " array([479.07548448]),\n",
       " array([2683.7150838]),\n",
       " array([1033.22463207]),\n",
       " array([233.61611669])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KMeans_fit.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "558c372d-1625-4571-a51d-593eee3578d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5ac51-feee-4056-b1d5-399fdf7af23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
